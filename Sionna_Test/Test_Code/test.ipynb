{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs available : 1\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Running with GPU\n",
      "Only GPU number 0 used.\n",
      "10\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "20\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "30\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "40\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "50\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "60\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "70\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "80\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "90\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "100\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Execution time: 3.128272771835327\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "If mode is 'interp', window_length must be less than or equal to the size of x.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 379\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mExecution time:\u001b[39m\u001b[39m\"\u001b[39m,time\u001b[39m.\u001b[39mtime()\u001b[39m-\u001b[39mstart)\n\u001b[0;32m    378\u001b[0m window_size \u001b[39m=\u001b[39m \u001b[39m7\u001b[39m\n\u001b[1;32m--> 379\u001b[0m ber_hat \u001b[39m=\u001b[39m savgol_filter(ber, window_size, \u001b[39m3\u001b[39;49m)\n\u001b[0;32m    380\u001b[0m ber2_hat \u001b[39m=\u001b[39m savgol_filter(ber2, window_size, \u001b[39m3\u001b[39m)\n\u001b[0;32m    381\u001b[0m ber3_hat \u001b[39m=\u001b[39m savgol_filter(ber3, window_size, \u001b[39m3\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\simon\\miniconda3\\envs\\tf2\\lib\\site-packages\\scipy\\signal\\_savitzky_golay.py:344\u001b[0m, in \u001b[0;36msavgol_filter\u001b[1;34m(x, window_length, polyorder, deriv, delta, axis, mode, cval)\u001b[0m\n\u001b[0;32m    342\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39minterp\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    343\u001b[0m     \u001b[39mif\u001b[39;00m window_length \u001b[39m>\u001b[39m x\u001b[39m.\u001b[39msize:\n\u001b[1;32m--> 344\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mIf mode is \u001b[39m\u001b[39m'\u001b[39m\u001b[39minterp\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, window_length must be less \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    345\u001b[0m                          \u001b[39m\"\u001b[39m\u001b[39mthan or equal to the size of x.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    347\u001b[0m     \u001b[39m# Do not pad. Instead, for the elements within `window_length // 2`\u001b[39;00m\n\u001b[0;32m    348\u001b[0m     \u001b[39m# of the ends of the sequence, use the polynomial that is fitted to\u001b[39;00m\n\u001b[0;32m    349\u001b[0m     \u001b[39m# the last `window_length` elements.\u001b[39;00m\n\u001b[0;32m    350\u001b[0m     y \u001b[39m=\u001b[39m convolve1d(x, coeffs, axis\u001b[39m=\u001b[39maxis, mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mconstant\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: If mode is 'interp', window_length must be less than or equal to the size of x."
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Rayleigh Experiment v2.ipynb\n",
    "\n",
    "Automatically generated by Colaboratory.\n",
    "\n",
    "Original file is located at\n",
    "    https://colab.research.google.com/drive/1Lj6h_Ms3gcbcA5jsXz6hMKP92o--Ubtl\n",
    "\"\"\"\n",
    "\n",
    "# Commented out IPython magic to ensure Python compatibility.\n",
    "from scipy import constants\n",
    "from scipy.spatial import distance\n",
    "from scipy.signal import savgol_filter\n",
    "from multiprocessing import Process\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print('Number of GPUs available :', len(gpus))\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "test_gpu = True\n",
    "\n",
    "if test_gpu == True:\n",
    "    print(\"Running with GPU\")\n",
    "    if gpus:\n",
    "        gpu_num = 0 # Number of the GPU to be used\n",
    "        try:\n",
    "            tf.config.set_visible_devices(gpus[gpu_num], 'GPU')\n",
    "            print('Only GPU number', gpu_num, 'used.')\n",
    "            tf.config.experimental.set_memory_growth(gpus[gpu_num], True)\n",
    "        except RuntimeError as e:\n",
    "            print(e)\n",
    "if test_gpu == False:\n",
    "        print(\"Running with CPU\")\n",
    "\n",
    "try:\n",
    "    import sionna as sn\n",
    "except ImportError as e:\n",
    "    # Install Sionna if package is not already installed\n",
    "    import os\n",
    "    os.system(\"pip install sionna\")\n",
    "    import sionna as sn\n",
    "\n",
    "# For plotting\n",
    "# %matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For the implementation of the Keras models\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "class Large_Scale_Fading():\n",
    "  def __init__(self, num_ut, num_bs, num_ut_ant, num_bs_ant, reference_distance = 10, frequency = 3e9, path_loss_exponent = 2.7, test1 = False, show_plot = False, simple_Test = False):\n",
    "    self.num_ut = num_ut\n",
    "    self.num_bs = num_bs\n",
    "    self.num_ut_ant = num_ut_ant\n",
    "    self.num_bs_ant = num_bs_ant\n",
    "    self.c = constants.speed_of_light\n",
    "    self.d_0 = reference_distance\n",
    "    self.f_0 = frequency \n",
    "    self.gamma = path_loss_exponent\n",
    "    self.test_1 = test1\n",
    "    self.show_plot = show_plot\n",
    "    self.simple_test = simple_Test\n",
    "\n",
    "  def calc_large_fading_coefficient(self, distance, db=False):\n",
    "    if (distance > self.d_0):\n",
    "      beta_db = (-20*np.log10(((4*constants.pi*self.d_0)/self.c)*self.f_0)) - (10*self.gamma*np.log10(distance/self.d_0))\n",
    "    else: \n",
    "      beta_db = -20*np.log10(((4*constants.pi*distance)/self.c)*self.f_0)\n",
    "    beta = np.power(10, beta_db/10)\n",
    "\n",
    "    if db:\n",
    "      return beta_db\n",
    "    else:\n",
    "      return beta\n",
    "\n",
    "  def generate_array(self, distance_to_BS=0):\n",
    "    # Code for generating random BS and UT.\n",
    "    if self.test_1 == True:\n",
    "      if self.num_bs == 3:\n",
    "        bs = np.array([[-100, 0], [0, 0], [100, 0]])\n",
    "      else:\n",
    "        bs = np.array([[0, 0]])\n",
    "      ut = np.array([[0, distance_to_BS]])\n",
    "    else:\n",
    "      bs = np.random.randint(low=-30, high=30, size=(self.num_bs, 2))\n",
    "      ut = np.random.randint(low=-30, high=30, size=(self.num_ut, 2))\n",
    "\n",
    "    #Generate Plot of BS and UTs\n",
    "    if self.show_plot:\n",
    "      for i in range(self.num_bs):\n",
    "        plt.scatter(bs[i,0], bs[i,1])\n",
    "        plt.annotate(f\"BS-{i}\", (bs[i,0], bs[i,1]))\n",
    "\n",
    "      for i in range(self.num_ut):\n",
    "        plt.scatter(ut[i,0], ut[i,1])\n",
    "        ut_num = \"UT_\" + str(i)\n",
    "        plt.annotate(ut_num, (ut[i,0], ut[i,1]))\n",
    "      plt.title(\"Location of BS and UT(s)\")\n",
    "      plt.show()\n",
    "\n",
    "    # Generate Array of distances between BS(s) and UT(s). Entry i, j is the distance between BS-i and UT-j. \n",
    "    self.distance_array = np.zeros([self.num_bs, self.num_ut])\n",
    "    for i in range(self.num_bs):\n",
    "      for j in range(self.num_ut):\n",
    "        self.distance_array[i, j] = distance.euclidean(bs[i], ut[j])\n",
    "\n",
    "    # Generate Array of path loss.\n",
    "    self.path_loss_array = np.zeros([1, self.num_bs, self.num_bs_ant, self.num_ut, self.num_ut_ant, 1, 1], dtype=np.float64)\n",
    "    for i in range(self.num_bs):\n",
    "      for j in range(self.num_ut):\n",
    "        self.path_loss_array[0, i, :, j, :, 0, 0] = self.calc_large_fading_coefficient(self.distance_array[i,j])\n",
    "    self.path_loss_array = tf.complex(np.float32(self.path_loss_array), tf.zeros(1, dtype=tf.float32))\n",
    "\n",
    "  def get_coefficients(self, ut_number):\n",
    "    ind = np.argmin(self.distance_array, axis=0)\n",
    "    return ind[ut_number]\n",
    "\n",
    "  def __call__(self, h_freq, distance_to_BS=0):\n",
    "    if self.simple_test == True:\n",
    "      h_faded = h_freq*np.sqrt(distance_to_BS)\n",
    "\n",
    "    else:\n",
    "      # generate path loss array\n",
    "      self.generate_array(distance_to_BS)\n",
    "\n",
    "      # Broadcast shape of path loss array to shape of channel\n",
    "      self.path_loss_array = tf.broadcast_to(self.path_loss_array, h_freq.shape)\n",
    "\n",
    "      # Apply path loss\n",
    "      h_faded = h_freq*np.sqrt(self.path_loss_array)\n",
    "\n",
    "    return h_faded\n",
    "\n",
    "class Data_Aggregation():\n",
    "  def __init__(self, num_ut, num_ut_ant, Large_Scale_Fading):\n",
    "    self._num_ut = num_ut\n",
    "    self._num_ut_ant = num_ut_ant\n",
    "    self._large_scale_fading = Large_Scale_Fading\n",
    "\n",
    "  def __call__(self, batch_size, b_hat, weighted=False):\n",
    "    b_final = np.zeros(b_hat[0].shape)\n",
    "    if weighted == False:\n",
    "      for h in range(batch_size):\n",
    "        for j in range(self._num_ut):\n",
    "          for k in range(self._num_ut_ant):\n",
    "            for i in range(tf.shape(b_final)[3]):\n",
    "              ones = 0\n",
    "              zeros = 0\n",
    "              for z in b_hat:\n",
    "                if z[h, j, k, i] == 1:\n",
    "                  ones += 1\n",
    "                else: \n",
    "                  zeros += 1\n",
    "              if ones > zeros:\n",
    "                b_final[h, j, k, i] = 1\n",
    "              elif ones < zeros:\n",
    "                b_final[h, j, k, i] = 0\n",
    "              else:\n",
    "                # Equal amount of 1s and 0s. Even amout of BS.\n",
    "                # Get which BS has lowest distance to the UT\n",
    "                x = self._large_scale_fading.get_coefficients(j)\n",
    "                b_final[h, j, k, i] = b_hat[x][h, j, k, i]\n",
    "\n",
    "    if weighted == True:\n",
    "      total_distance = np.sum(self._large_scale_fading.distance_array, axis=0)\n",
    "      for h in range(batch_size):\n",
    "        for j in range(self._num_ut):\n",
    "          for k in range(self._num_ut_ant):\n",
    "            for i in range(tf.shape(b_final)[3]):\n",
    "              value = 0\n",
    "              for z in range(len(b_hat)):\n",
    "                if b_hat[z][h, j, k, i] == 0:\n",
    "                  value += (np.log10(total_distance[j])-np.log10(self._large_scale_fading.distance_array[z, j]))/np.log10(total_distance[j])*(-1)\n",
    "                else:\n",
    "                  value += (np.log10(total_distance[j])-np.log10(self._large_scale_fading.distance_array[z, j]))/np.log10(total_distance[j])*(1)\n",
    "              \n",
    "              if value < 0:\n",
    "                b_final[h, j, k, i] = 0\n",
    "              else:\n",
    "                b_final[h, j, k, i] = 1\n",
    "\n",
    "    return b_final\n",
    "\n",
    "class TestModel(Model):\n",
    "  def __init__(self, num_ut, num_bs, num_ut_ant, num_bs_ant, perfect_csi, cell_free = False):\n",
    "    super().__init__()\n",
    "\n",
    "    self._num_bits_per_symbol = 2\n",
    "    self.cell_free = cell_free\n",
    "    # Set BS and UT stuff\n",
    "    self._num_ut = num_ut\n",
    "    self._num_bs = num_bs\n",
    "    self._num_ut_ant = num_ut_ant\n",
    "    self._num_bs_ant = num_bs_ant\n",
    "    self._num_streams_per_tx = self._num_ut_ant\n",
    "    self._perfect_csi = perfect_csi\n",
    "\n",
    "    # Setup Stream Management\n",
    "    if self.cell_free:\n",
    "      self._rx_tx_association = np.zeros([1, self._num_ut])\n",
    "      self._rx_tx_association[0, :] = 1\n",
    "      self._stream_management = sn.mimo.StreamManagement(self._rx_tx_association, self._num_streams_per_tx)\n",
    "    else:\n",
    "      self._rx_tx_association = np.zeros([self._num_bs, self._num_ut])\n",
    "      self._rx_tx_association[0, :] = 1\n",
    "      self._stream_management = sn.mimo.StreamManagement(self._rx_tx_association, self._num_streams_per_tx)\n",
    "\n",
    "    # Setup OFDM Resource Grid\n",
    "    self._rg = sn.ofdm.ResourceGrid(num_ofdm_symbols=14,\n",
    "                                      fft_size=76,\n",
    "                                      subcarrier_spacing=30e3,\n",
    "                                      num_tx=self._num_ut,\n",
    "                                      num_streams_per_tx=self._num_streams_per_tx,\n",
    "                                      cyclic_prefix_length=6,\n",
    "                                      pilot_pattern=\"kronecker\",\n",
    "                                      pilot_ofdm_symbol_indices=[2,11])\n",
    "\n",
    "    self._n = int(self._rg.num_data_symbols*self._num_bits_per_symbol)\n",
    "    \n",
    "    # Instantiate modules\n",
    "    self._binary_source = sn.utils.BinarySource()\n",
    "    self._mapper = sn.mapping.Mapper(\"qam\", self._num_bits_per_symbol)\n",
    "    self._rg_mapper = sn.ofdm.ResourceGridMapper(self._rg)\n",
    "    self._large_scale_fading = Large_Scale_Fading(self._num_ut, self._num_bs, self._num_ut_ant, self._num_bs_ant, test1=True, show_plot = False, simple_Test = False)\n",
    "    self._rayleigh_fading = sn.channel.RayleighBlockFading(self._num_bs, self._num_bs_ant, self._num_ut, self._num_ut_ant)\n",
    "    self._generate_channel = sn.channel.GenerateOFDMChannel(self._rayleigh_fading, self._rg, normalize_channel=True)\n",
    "    self._apply_channel = sn.channel.ApplyOFDMChannel(add_awgn=True)\n",
    "    self._ls_est = sn.ofdm.LSChannelEstimator(self._rg, interpolation_type=\"nn\")\n",
    "    self._remove_nulled_subcarriers = sn.ofdm.RemoveNulledSubcarriers(self._rg)\n",
    "    self._lmmse_equ = sn.ofdm.LMMSEEqualizer(self._rg, self._stream_management)\n",
    "    self._demapper = sn.mapping.Demapper(\"app\", \"qam\", self._num_bits_per_symbol, hard_out=\"True\")\n",
    "    self._data_aggregation = Data_Aggregation(self._num_ut, self._num_ut_ant, self._large_scale_fading)\n",
    "\n",
    "  def call(self, batch_size, beta = 1, weighted=False):\n",
    "    #no = sn.utils.ebnodb2no(ebno_db=30, num_bits_per_symbol=self._num_bits_per_symbol, coderate=1, resource_grid=self._rg)\n",
    "    \n",
    "    no_db = -110\n",
    "    no = tf.constant([np.power(10, no_db/10)], dtype=tf.float32)\n",
    "\n",
    "    bits = self._binary_source([batch_size, self._num_ut, self._rg.num_streams_per_tx, self._n])\n",
    "    x = self._mapper(bits)\n",
    "    x_rg = self._rg_mapper(x)\n",
    "    \n",
    "    # Generate Channel\n",
    "    h_freq = self._generate_channel(batch_size)\n",
    "\n",
    "    # Apply Large Scale Fading to channel\n",
    "    h_freq_hat = self._large_scale_fading(h_freq, distance_to_BS = beta)\n",
    "\n",
    "    # Apply Channel\n",
    "    y = self._apply_channel((x_rg, h_freq_hat, no))\n",
    "\n",
    "    # Use perfect CSI or Channel Estimator\n",
    "    if self._perfect_csi:\n",
    "        h_hat = self._remove_nulled_subcarriers(h_freq)\n",
    "        err_var = 0.0\n",
    "    else:\n",
    "        h_hat, err_var = self._ls_est ([y, no])\n",
    "    \n",
    "    if self.cell_free:\n",
    "      # Split channel tensor into num_bs tensors\n",
    "      h_hat = tf.split(h_hat, num_or_size_splits=self._num_bs, axis=1)\n",
    "\n",
    "      # Split received symbols tensor into num_bs tensors\n",
    "      y = tf.split(y, num_or_size_splits=self._num_bs, axis=1)\n",
    "\n",
    "      # Apply LMMSE Equalizer for each BS\n",
    "      b_hat = []\n",
    "      for i, j in zip(y, h_hat):\n",
    "        x_hat, no_eff = self._lmmse_equ([i, j, err_var, no])\n",
    "        b_hat.append(self._demapper([x_hat, no_eff]))\n",
    "      \n",
    "      # Do majority vote to find final bits\n",
    "      b_final =  self._data_aggregation(batch_size, b_hat, weighted=weighted)\n",
    "    \n",
    "    else:\n",
    "      x_hat, no_eff = self._lmmse_equ([y, h_hat, err_var, no])\n",
    "      b_final = self._demapper([x_hat, no_eff])\n",
    "\n",
    "\n",
    "    return bits, b_final\n",
    "\n",
    "def task(arg, x, x1, x2, x3):\n",
    "    print(f'.done {arg}', flush=True)\n",
    "    print(\"SHIT!\")\n",
    "    \n",
    "    print(\"Tests no:\",tests)\n",
    "    for i in range(tests):\n",
    "      b, b_hat = model(batch_size=batch_size, beta=arg, weighted=False)\n",
    "      print(f\"b={b}, b_hat={b_hat} first\")\n",
    "      x1 += sn.utils.metrics.compute_ber(b, b_hat)\n",
    "      print(f\"x1 = {x1}\")\n",
    "\n",
    "      b, b_hat = model(batch_size=batch_size, beta=arg, weighted=True)\n",
    "      print(f\"b={b}, b_hat={b_hat} second\")\n",
    "      x2 += sn.utils.metrics.compute_ber(b, b_hat)\n",
    "      print(f\"x2 = {x2}\")\n",
    "\n",
    "      b, b_hat = model2(batch_size=batch_size, beta=arg)\n",
    "      print(f\"b={b}, b_hat={b_hat} third\")\n",
    "      x3 += sn.utils.metrics.compute_ber(b, b_hat)\n",
    "      print(f\"x3 = {x3}\")\n",
    "\n",
    "    ber.append(x1/tests)\n",
    "    ber2.append(x2/tests)\n",
    "    ber3.append(x3/tests)\n",
    "    x.append(arg)\n",
    "    print(f\"ber = {ber}\")\n",
    "    print(f\"ber2 = {ber2}\")\n",
    "    print(f\"ber3 = {ber3}\")\n",
    "    print(f\"x = {x}\")\n",
    "\n",
    "def testtask(arg, x, x1, x2, x3):\n",
    "    print(f'.done {arg}', flush=True)\n",
    "    print(\"SHIT!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  #ebno_db = 0\n",
    "  batch_size = 1\n",
    "\n",
    "  model = TestModel(num_ut=1, num_bs=3, num_ut_ant=1, num_bs_ant=64, perfect_csi = False, cell_free = True)\n",
    "  model2 = TestModel(num_ut=1, num_bs=1, num_ut_ant=1, num_bs_ant=64, perfect_csi = False, cell_free = False)\n",
    "  #model3 = TestModel(num_ut=1, num_bs=5, num_ut_ant=1, num_bs_ant=64, perfect_csi = False)\n",
    "  # ber = []\n",
    "  # x = []\n",
    "  # ber2 = []\n",
    "  # ber3 = []\n",
    "\n",
    "  # for i in range(3, 8):\n",
    "  #   for j in range(9, 0, -1):\n",
    "  #     b, b_hat = model(batch_size=batch_size, beta=j*10**-i, weighted=False)\n",
    "  #     ber.append(sn.utils.metrics.compute_ber(b, b_hat))\n",
    "  #     x.append(j*10**-i)\n",
    "  #     #b2, b_hat2 = model(batch_size=batch_size, beta=j*10**-i, weighted=True)\n",
    "  #     b3, b_hat3 = model2(batch_size=batch_size, beta=j*10**-i)\n",
    "  #     #ber2.append(sn.utils.metrics.compute_ber(b2, b_hat2))\n",
    "  #     ber3.append(sn.utils.metrics.compute_ber(b3, b_hat3))\n",
    "\n",
    "  # plt.rcParams[\"figure.figsize\"] = (12.8, 9.6)\n",
    "  # plt.loglog(x, ber, \"r\", label=\"Majority\")\n",
    "  # #plt.loglog(x, ber2, \"b\", label=\"Weighted\")\n",
    "  # plt.loglog(x, ber3, \"g\", label=\"Cellular\")\n",
    "  # plt.ylabel(\"Bit Error Rate (BER)\")\n",
    "  # plt.xlabel(\"Path Loss\")\n",
    "  # plt.gca().invert_xaxis()\n",
    "  # plt.legend()\n",
    "  # plt.show()\n",
    "\n",
    "  \n",
    "  ber = []\n",
    "  x = []\n",
    "  ber2 = []\n",
    "  ber3 = []\n",
    "  tests = 1\n",
    "\n",
    "  start = time.time()\n",
    "  for distance_to_bs in range(10, 110, 10):\n",
    "    print(distance_to_bs)\n",
    "    x1 = 0\n",
    "    x2 = 0\n",
    "    x3 = 0\n",
    "\n",
    "    processes = [Process(target=testtask, args=(i,x,x1,x2,x3)) for i in range(10,110,10)]\n",
    "\n",
    "    for process in processes:\n",
    "      process.start()\n",
    "    for process in processes:\n",
    "      process.join()\n",
    "      print('Done', flush=True)\n",
    "\n",
    "  print(\"Execution time:\",time.time()-start)\n",
    "\n",
    "  window_size = 7\n",
    "  ber_hat = savgol_filter(ber, window_size, 3)\n",
    "  ber2_hat = savgol_filter(ber2, window_size, 3)\n",
    "  ber3_hat = savgol_filter(ber3, window_size, 3)\n",
    "\n",
    "  plt.rcParams[\"figure.figsize\"] = (12.8, 9.6)\n",
    "  plt.plot(x, ber_hat, \"g\", label=\"Majority Vote\")\n",
    "  plt.plot(x, ber2_hat, \"r\", label=\"Weighted Vote\")\n",
    "  plt.plot(x, ber3_hat, \"b\", label=\"Cellular\")\n",
    "\n",
    "  #plt.yscale(\"symlog\", linthreshy=1e-7)\n",
    "  #ax.plot(x, ber, \"g\")\n",
    "  #ax.set_yscale(\"symlog\")\n",
    "  # plt.semilogy(x, ber2_hat, \"r\", label=\"Weighted Vote\")\n",
    "  # plt.semilogy(x, ber3_hat, \"b\", label=\"Cellular\")\n",
    "  # ax.set_ylabel(\"Bit Error Rate (BER)\")\n",
    "  # ax.set_xlabel(\"Distance [m]\")\n",
    "  #ax.set_ylim(([0, 5e-1]))\n",
    "  #plt.xticks(np.arange(min(x), max(x)+1, 100))\n",
    "  # ax.set_ylim([1e-3, 1e0])\n",
    "  # ax.set_yticks([1e-3, 1e-2, 1e-1])\n",
    "  # ax.grid()\n",
    "  # ax.legend()\n",
    "  plt.ylabel(\"Bit Error Rate (BER)\")\n",
    "  plt.xlabel(\"Distance [m]\")\n",
    "  plt.ylim([1e-6, 1e0])\n",
    "  plt.xlim([0, 2000])\n",
    "  plt.xticks(np.arange(0, 2000, 100))\n",
    "  plt.legend()\n",
    "  plt.grid()\n",
    "  # plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e63a3201faa886433f053ac850182e6ced7152f08f157297f57004497d3b522a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
