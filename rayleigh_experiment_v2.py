# -*- coding: utf-8 -*-
"""Rayleigh Experiment v2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Lj6h_Ms3gcbcA5jsXz6hMKP92o--Ubtl
"""

# Commented out IPython magic to ensure Python compatibility.
from scipy import constants
from scipy.spatial import distance
import tensorflow as tf
import numpy as np

gpus = tf.config.list_physical_devices('GPU')
print('Number of GPUs available :', len(gpus))
if gpus:
    gpu_num = 0 # Number of the GPU to be used
    try:
        tf.config.set_visible_devices(gpus[gpu_num], 'GPU')
        print('Only GPU number', gpu_num, 'used.')
        tf.config.experimental.set_memory_growth(gpus[gpu_num], True)
    except RuntimeError as e:
        print(e)

try:
    import sionna as sn
except ImportError as e:
    # Install Sionna if package is not already installed
    import os
    os.system("pip install sionna")
    import sionna as sn

# For plotting
# %matplotlib inline
import matplotlib.pyplot as plt

# For the implementation of the Keras models
from tensorflow.keras import Model

class Large_Scale_Fading():
  def __init__(self, num_ut, num_bs, reference_distance = 10, frequency = 3e9, path_loss_exponent = 2.7):
    self.num_ut = num_ut
    self.num_bs = num_bs
    self.large_fading_coefficients = np.zeros([1, self.num_ut, 1, 1, 1])
    self.c = constants.speed_of_light
    self.d_0 = reference_distance
    self.f_0 = frequency 
    self.gamma = path_loss_exponent

  def calc_large_fading_coefficient(self, distance):
    if (distance > self.d_0):
      beta_db = (-20*np.log10(((4*constants.pi*self.d_0)/self.c)*self.f_0)) - (10*self.gamma*np.log10(distance/self.d_0))
    else: 
      beta_db = -20*np.log10(((4*constants.pi*distance)/self.c)*self.f_0)

    beta = np.power(10, beta_db/10)
    return beta

  def generate_array(self):
    bs = np.array([[-20, 0], [20, 0]])
    ut = np.random.randint(low=-30, high=30, size=(self.num_ut, 2))
    #Generate Plot of BS and UTs

    for i in range(self.num_bs):
      plt.scatter(bs[i,0], bs[i,1])
      plt.annotate(f"BS-{i}", (bs[i,0], bs[i,1]))

    for i in range(self.num_ut):
      plt.scatter(ut[i,0], ut[i,1])
      ut_num = "UT_" + str(i)
      plt.annotate(ut_num, (ut[i,0], ut[i,1]))
    plt.title("Location of BS and UT(s)")
    plt.show()

    for i in range(self.num_ut):
      dist = distance.euclidean(bs[i], ut[i])
      self.large_fading_coefficients[0, i, 0, 0, 0] = self.calc_large_fading_coefficient(dist)
    self.large_fading_coefficients = tf.complex(np.float32(self.large_fading_coefficients), tf.zeros(1, dtype=tf.float32))

  def __call__(self, x_rg):
    self.generate_array()
    self.large_scale_coefficients = tf.broadcast_to(self.large_fading_coefficients, [1, self.num_ut, 1, 14, 76])
    x_rg_hat = x_rg*np.sqrt(self.large_scale_coefficients)
    
    return x_rg_hat

class TestModel(Model):
  def __init__(self, num_ut, num_bs, num_ut_ant, num_bs_ant, perfect_csi):
    super().__init__()

    self._num_bits_per_symbol = 2

    # Set BS and UT stuff
    self._num_ut = num_ut
    self._num_bs = num_bs
    self._num_ut_ant = num_ut_ant
    self._num_bs_ant = num_bs_ant
    self._num_streams_per_tx = self._num_ut_ant
    self._perfect_csi = perfect_csi

    # Setup Stream Management
    self._rx_tx_association = np.zeros([1, self._num_ut])
    self._rx_tx_association[0, :] = 1
    self._stream_management = sn.mimo.StreamManagement(self._rx_tx_association, self._num_streams_per_tx)

    # Setup OFDM Resource Grid
    self._rg = sn.ofdm.ResourceGrid(num_ofdm_symbols=14,
                                      fft_size=76,
                                      subcarrier_spacing=30e3,
                                      num_tx=self._num_ut,
                                      num_streams_per_tx=self._num_streams_per_tx,
                                      cyclic_prefix_length=6,
                                      pilot_pattern="kronecker",
                                      pilot_ofdm_symbol_indices=[2,11])

    self._n = int(self._rg.num_data_symbols*self._num_bits_per_symbol)
    
    # Instantiate modules
    self._binary_source = sn.utils.BinarySource()
    self._mapper = sn.mapping.Mapper("qam", self._num_bits_per_symbol)
    self._rg_mapper = sn.ofdm.ResourceGridMapper(self._rg)
    self._large_scale_fading = Large_Scale_Fading(self._num_ut, self._num_bs)
    self._rayleigh_fading = sn.channel.RayleighBlockFading(self._num_bs, self._num_bs_ant, self._num_ut, self._num_ut_ant)
    self._channel = sn.channel.OFDMChannel(self._rayleigh_fading, self._rg, add_awgn=True, normalize_channel=True, return_channel=True)
    self._ls_est = sn.ofdm.LSChannelEstimator(self._rg, interpolation_type="nn")
    self._remove_nulled_subcarriers = sn.ofdm.RemoveNulledSubcarriers(self._rg)
    self._lmmse_equ = sn.ofdm.LMMSEEqualizer(self._rg, self._stream_management)
    self._demapper = sn.mapping.Demapper("app", "qam", self._num_bits_per_symbol, hard_out="True")

  def call(self, batch_size, beta = 0):
    no = sn.utils.ebnodb2no(ebno_db=30, num_bits_per_symbol=self._num_bits_per_symbol, coderate=1, resource_grid=self._rg)
    bits = self._binary_source([batch_size, self._num_ut, self._rg.num_streams_per_tx, self._n])
    x = self._mapper(bits)
    x_rg = self._rg_mapper(x)
    
    if beta != 0:
      x_faded = x_rg*np.sqrt(beta)
    else:
      x_faded = self._large_scale_fading(x_rg)

    y, h_freq = self._channel([x_faded, no])
      
    # Use perfect CSI or Channel Estimator
    if self._perfect_csi:
        h_hat = self._remove_nulled_subcarriers(h_freq)
        err_var = 0.0
    else:
        h_hat, err_var = self._ls_est ([y, no])
    
    # Split channel tensor into num_bs tensors. Basically separates the channel for each BS
    h_hat = tf.split(h_hat, num_or_size_splits=self._num_bs, axis=1)

    # Apply OFDM channel to mapped symbols
    y = tf.split(y, num_or_size_splits=self._num_bs, axis=1)
    
    # Apply LMMSE Equalizer for each BS
    counter = 0
    b_hat = []
    for i in y:
      x_hat, no_eff = self._lmmse_equ([i, h_hat[counter], err_var, no])
      counter += 1
      b_hat.append(self._demapper([x_hat, no_eff]))
    
    # Do majority vote to find final bits
    b_final = np.zeros(b_hat[0].shape)
    for i in range(tf.shape(b_final)[3]):
      ones = 0
      zeros = 0
      for z in b_hat:
        if z[0, 0, 0, i] == 1:
          ones += 1
        else: 
          zeros += 1
      if ones > zeros:
        b_final[0, 0, 0, i] = 1
      else:
        b_final[0, 0, 0, i] = 0

    return bits, b_final

#ebno_db = 0
batch_size = 1

model = TestModel(num_ut=1, num_bs=1, num_ut_ant=1, num_bs_ant=64, perfect_csi = True)
# model2 = TestModel(num_ut=1, num_bs=3, num_ut_ant=1, num_bs_ant=64, perfect_csi = True)
# model3 = TestModel(num_ut=1, num_bs=5, num_ut_ant=1, num_bs_ant=64, perfect_csi = True)
ber = []
x = []
# ber2 = []
# ber3 = []

for i in range(4, 11):
  for j in range(9, 0, -1):
    b, b_hat = model(batch_size=batch_size, beta=j*10**-i)
    ber.append(sn.utils.metrics.compute_ber(b, b_hat))
    x.append(j*10**-i)
    # b2, b_hat2 = model2(batch_size=batch_size, beta=j*10**-i)
    # b3, b_hat3 = model3(batch_size=batch_size, beta=j*10**-i)
    # ber2.append(sn.utils.metrics.compute_ber(b2, b_hat2))
    # ber3.append(sn.utils.metrics.compute_ber(b3, b_hat3))

plt.rcParams["figure.figsize"] = (12.8, 9.6)
plt.loglog(x, ber, "r", label="1 BS")
# plt.loglog(x, ber2, "b", label="3 BS")
# plt.loglog(x, ber3, "g", label="5 BS")
plt.ylabel("Bit Error Rate (BER)")
plt.xlabel("Path Loss")
plt.gca().invert_xaxis()
plt.legend()
plt.show()

# ber = []
# x = []
# for i in range(1, 6, 2):
#   model = TestModel(num_ut=1, num_bs=i, num_ut_ant=1, num_bs_ant=64, perfect_csi = True)
#   b, b_hat = model(batch_size=batch_size, beta = 1)
# #print(f"Original bits: {b}")
# #b2, b_ha2t = model2(batch_size=batch_size, beta = 0)
#   ber.append(sn.utils.metrics.compute_ber(b, b_hat))
#   x.append(i)

# plt.rcParams["figure.figsize"] = (12.8, 9.6)
# plt.semilogy(x, ber, linewidth=5)
# plt.ylabel("Bit Error Rate (BER)")
# plt.xlabel("Number of basestations")
# #plt.gca().invert_xaxis()
# plt.show()

# ber2 = sn.utils.metrics.compute_ber(b_hat[0], b_hat[2])
# ber3 = sn.utils.metrics.compute_ber(b_hat[1], b_hat[2])
# nb_bits = np.size(b.numpy())
# print("BER: {:.4} at Eb/No of {} dB and {} simulated bits".format(ber.numpy(), 30, nb_bits))
# print("BER: {:.4} at Eb/No of {} dB and {} simulated bits".format(ber2.numpy(), 30, nb_bits))
# print("BER: {:.4} at Eb/No of {} dB and {} simulated bits".format(ber3.numpy(), 30, nb_bits))

#ber_final = sn.utils.metrics.compute_ber(b, b_hat)
#print(f"Majority vote output: {b_hat}")
#print("BER: {:.4} at Eb/No of {} dB and {} simulated bits".format(ber_final.numpy(), 30, nb_bits))